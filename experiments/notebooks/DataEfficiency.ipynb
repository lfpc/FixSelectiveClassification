{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and pre-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MAIN_PATH = r'/home/luis-felipe'\n",
    "DATA_PATH = os.path.join(MAIN_PATH,'data')\n",
    "PATH_MODELS = os.path.join(MAIN_PATH,'torch_models')\n",
    "FIGS_PATH = os.path.join(MAIN_PATH,'results','figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contrÃ¡rio\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.set_default_dtype(torch.float64)\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import models\n",
    "from utils import measures,metrics\n",
    "from data_utils import upload_logits, split_data\n",
    "import post_hoc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARC = 'resnet50'\n",
    "DATASET = 'ImageNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits,labels = upload_logits(MODEL_ARC,DATASET,PATH_MODELS, \n",
    "                            split = 'test', device = dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.1 #Size of total hold-out samples 0.1 = 5000)\n",
    "N_SPLITS_VAL_TEST = 50 #number of experiments of different splits of validation and test\n",
    "N_SPLIT_SUB_VAL = 1 #How many experiments for each random subset of the holdout\n",
    "SIZES_SUB = np.arange(0.025,1.01,0.025) #Hold-out sizes\n",
    "\n",
    "METRIC = metrics.N_AURC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "1\n",
      "1.0\n",
      "2\n",
      "2.0\n",
      "3\n",
      "3.0\n",
      "4\n",
      "4.0\n",
      "5\n",
      "5.0\n",
      "6\n",
      "6.0\n",
      "7\n",
      "7.0\n",
      "8\n",
      "8.0\n",
      "9\n",
      "9.0\n",
      "10\n",
      "10.0\n",
      "11\n",
      "11.0\n",
      "12\n",
      "12.0\n",
      "13\n",
      "13.0\n",
      "14\n",
      "14.0\n",
      "15\n",
      "15.0\n",
      "16\n",
      "16.0\n",
      "17\n",
      "17.0\n",
      "18\n",
      "18.0\n",
      "19\n",
      "19.0\n",
      "20\n",
      "20.0\n",
      "21\n",
      "21.0\n",
      "22\n",
      "22.0\n",
      "23\n",
      "23.0\n",
      "24\n",
      "24.0\n",
      "25\n",
      "25.0\n",
      "26\n",
      "26.0\n",
      "27\n",
      "27.0\n",
      "28\n",
      "28.0\n",
      "29\n",
      "29.0\n",
      "30\n",
      "30.0\n",
      "31\n",
      "31.0\n",
      "32\n",
      "32.0\n",
      "33\n",
      "33.0\n",
      "34\n",
      "34.0\n",
      "35\n",
      "35.0\n",
      "36\n",
      "36.0\n",
      "37\n",
      "37.0\n",
      "38\n",
      "38.0\n",
      "39\n",
      "39.0\n",
      "40\n",
      "40.0\n",
      "41\n",
      "41.0\n",
      "42\n",
      "42.0\n",
      "43\n",
      "43.0\n",
      "44\n",
      "44.0\n",
      "45\n",
      "45.0\n",
      "46\n",
      "46.0\n",
      "47\n",
      "47.0\n",
      "48\n",
      "48.0\n",
      "49\n",
      "49.0\n",
      "CPU times: user 2h 4min 11s, sys: 964 ms, total: 2h 4min 12s\n",
      "Wall time: 2h 4min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "exp_1 = []\n",
    "exp_1_opt = defaultdict(list)\n",
    "seed1 = SEED\n",
    "seed2 = 1\n",
    "for r1 in range(N_SPLITS_VAL_TEST):\n",
    "    print(r1)\n",
    "    logits_val,labels_val,logits_test,labels_test = split_data.split_logits(logits,labels,VAL_SIZE,seed=seed1)\n",
    "    loss_test = measures.wrong_class(logits_test,labels_test).float()\n",
    "\n",
    "    exp_1_opt['baseline'].append(METRIC(loss_test,measures.MSP(logits_test)))\n",
    "    exp_1_opt['T'].append(METRIC(loss_test,measures.MSP(logits_test.div(post_hoc.optimize.T(logits_test,loss_test)))))\n",
    "    exp_1_opt['p'].append(METRIC(loss_test,post_hoc.MaxLogit_pNorm(logits_test,risk = loss_test)))\n",
    "    pT = post_hoc.optimize.p_and_T(logits_test,loss_test,method = measures.MSP)\n",
    "    exp_1_opt['MSP-p'].append(METRIC(loss_test,measures.MSP(post_hoc.normalize(logits_test,pT[0]).div(pT[1]))))\n",
    "    exp_1_opt['LogitsMargin'].append(METRIC(loss_test,measures.margin_logits(logits_test)))\n",
    "\n",
    "\n",
    "    exp_2 = []\n",
    "    for r2 in range(N_SPLIT_SUB_VAL):\n",
    "        print(f'{r1}.{r2}')\n",
    "        exp_3 = defaultdict(list)\n",
    "        for val_size_sub in SIZES_SUB:\n",
    "            N = labels_val.size(0)\n",
    "            logits_sub,labels_sub =logits_val[:int(val_size_sub*N)],labels_val[:int(val_size_sub*N)]#= split_data.split_logits(logits_val,labels_val,val_size_sub,seed = seed2)[:2]\n",
    "            loss_sub = measures.wrong_class(logits_sub,labels_sub).float()\n",
    "            exp_3['T'].append(METRIC(loss_test,measures.MSP(logits_test.div(post_hoc.optimize.T(logits_sub,loss_sub)))))\n",
    "            p = post_hoc.optimize.p(logits_sub,loss_sub,method = measures.max_logit)\n",
    "            exp_3['p'].append(METRIC(loss_test,post_hoc.MaxLogit_pNorm(logits_test,p = p)))\n",
    "            pT = post_hoc.optimize.p_and_T(logits_sub,loss_sub,method = measures.MSP)\n",
    "            exp_3['MSP-p'].append(METRIC(loss_test,measures.MSP(post_hoc.normalize(logits_test,pT[0]).div(pT[1]))))\n",
    "            exp_3['LogitsMargin'].append(METRIC(loss_test,measures.margin_logits(logits_test)))\n",
    "            #p = post_hoc.optimize.p(logits_sub,loss_sub,method = measures.margin_logits)\n",
    "            #exp_3['LogitsMargin-pNorm'].append(METRIC(loss_test,measures.margin_logits(post_hoc.normalize(logits_test,p=p))))\n",
    "\n",
    "            \n",
    "            seed2 += 10\n",
    "        exp_2.append(exp_3)\n",
    "    exp_1.append(exp_2)\n",
    "    seed1 += 10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'exp_1_dataefficiency_{MODEL_ARC}_{DATASET}.pickle', 'wb') as handle:\n",
    "    pickle.dump(exp_1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#with open(f'exp_1_dataefficiency_{MODEL_ARC}_{DATASET}.pickle', 'rb') as handle:\n",
    "#    exp_1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sizes_sub = labels.size(0)*VAL_SIZE*np.r_[SIZES_SUB,1.0]\n",
    "sizes_sub = labels.size(0)*VAL_SIZE*SIZES_SUB\n",
    "all_t = []\n",
    "all_p = []\n",
    "all_pT = []\n",
    "all_2T = []\n",
    "all_LM = []\n",
    "all_LM_p = []\n",
    "for r1 in exp_1:\n",
    "    for r2 in r1:\n",
    "        all_t.append(r2['T'])\n",
    "        all_p.append(r2['p'])\n",
    "        all_pT.append(r2['MSP-p'])\n",
    "        all_2T.append(r2['MSP-2'])\n",
    "        all_LM.append(r2['LogitsMargin'])\n",
    "        all_LM_p.append(r2['LogitsMargin-pNorm'])\n",
    "all_t = np.array(all_t)\n",
    "all_p = np.array(all_p)\n",
    "all_pT = np.array(all_pT)\n",
    "all_2T = np.array(all_2T)\n",
    "all_LM = np.array(all_LM)\n",
    "all_LM_p = np.array(all_LM_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis-felipe/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/luis-felipe/miniconda3/lib/python3.10/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m p_opt_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(exp_1_opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     40\u001b[0m pT_opt_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(exp_1_opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSP-p\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 41\u001b[0m T2_opt_min \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_1_opt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMSP-2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m LM_opt_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(exp_1_opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitsMargin\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#LM_p_opt_min = np.min(exp_1_opt['LogitsMargin-pNorm'])\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2946\u001b[0m, in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2829\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[1;32m   2830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2831\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2832\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2833\u001b[0m \u001b[38;5;124;03m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[1;32m   2834\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;124;03m    6\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2947\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "means_T = all_t.mean(0)\n",
    "means_p = all_p.mean(0)\n",
    "means_pT = all_pT.mean(0)\n",
    "means_2T = all_2T.mean(0)\n",
    "means_LM = all_LM.mean(0)\n",
    "means_LM_p = all_LM_p.mean(0)\n",
    "\n",
    "std_T = all_t.std(0)\n",
    "std_p = all_p.std(0)\n",
    "std_pT = all_pT.std(0)\n",
    "std_2T = all_2T.std(0)\n",
    "std_LM = all_LM.std(0)\n",
    "std_LM_p = all_LM_p.std(0)\n",
    "\n",
    "min_T = all_t.min(0)\n",
    "min_p = all_p.min(0)\n",
    "min_pT = all_pT.min(0)\n",
    "min_2T = all_2T.min(0)\n",
    "min_LM = all_LM.min(0)\n",
    "min_LM_p = all_LM_p.min(0)\n",
    "\n",
    "max_T = all_t.max(0)\n",
    "max_p = all_p.max(0)\n",
    "max_pT = all_pT.max(0)\n",
    "max_2T = all_2T.max(0)\n",
    "max_LM = all_LM.max(0)\n",
    "max_LM_p = all_LM_p.max(0)\n",
    "\n",
    "baseline_mean = np.mean(exp_1_opt['baseline'])\n",
    "T_opt_mean = np.mean(exp_1_opt['T'])\n",
    "p_opt_mean = np.mean(exp_1_opt['p'])\n",
    "pT_opt_mean = np.mean(exp_1_opt['MSP-p'])\n",
    "T2_opt_mean = np.mean(exp_1_opt['MSP-2'])\n",
    "LM_opt_mean = np.mean(exp_1_opt['LogitsMargin'])\n",
    "#LM_p_opt_mean = np.mean(exp_1_opt['LogitsMargin-pNorm'])\n",
    "\n",
    "baseline_min = np.min(exp_1_opt['baseline'])\n",
    "T_opt_min = np.min(exp_1_opt['T'])\n",
    "p_opt_min = np.min(exp_1_opt['p'])\n",
    "pT_opt_min = np.min(exp_1_opt['MSP-p'])\n",
    "T2_opt_min = np.min(exp_1_opt['MSP-2'])\n",
    "LM_opt_min = np.min(exp_1_opt['LogitsMargin'])\n",
    "#LM_p_opt_min = np.min(exp_1_opt['LogitsMargin-pNorm'])\n",
    "\n",
    "baseline_max = np.max(exp_1_opt['baseline'])\n",
    "T_opt_max = np.max(exp_1_opt['T'])\n",
    "p_opt_max = np.max(exp_1_opt['p'])\n",
    "pT_opt_max = np.max(exp_1_opt['MSP-p'])\n",
    "T2_opt_max = np.max(exp_1_opt['MSP-2'])\n",
    "LM_opt_max = np.max(exp_1_opt['LogitsMargin'])\n",
    "#LM_p_opt_max = np.max(exp_1_opt['LogitsMargin-pNorm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTILES = (10,90)\n",
    "per_T_0 = np.percentile(all_t,PERCENTILES[0],axis=0)\n",
    "per_p_0 = np.percentile(all_p,PERCENTILES[0],axis=0)\n",
    "per_pT_0 = np.percentile(all_pT,PERCENTILES[0],axis=0)\n",
    "per_2T_0 = np.percentile(all_2T,PERCENTILES[0],axis=0)\n",
    "per_LM_0 = np.percentile(all_LM,PERCENTILES[0],axis=0)\n",
    "per_LM_p_0 = np.percentile(all_LM_p,PERCENTILES[0],axis=0)\n",
    "\n",
    "per_T_1 = np.percentile(all_t,PERCENTILES[1],axis=0)\n",
    "per_p_1 = np.percentile(all_p,PERCENTILES[1],axis=0)\n",
    "per_pT_1 = np.percentile(all_pT,PERCENTILES[1],axis=0)\n",
    "per_2T_1 = np.percentile(all_2T,PERCENTILES[1],axis=0)\n",
    "per_LM_1 = np.percentile(all_LM,PERCENTILES[1],axis=0)\n",
    "per_LM_p_1 = np.percentile(all_LM_p,PERCENTILES[1],axis=0)\n",
    "\n",
    "per_T_0_opt = np.percentile(exp_1_opt['T'],PERCENTILES[0],axis=0)\n",
    "per_p_0_opt = np.percentile(exp_1_opt['p'],PERCENTILES[0],axis=0)\n",
    "per_pT_0_opt = np.percentile(exp_1_opt['MSP-p'],PERCENTILES[0],axis=0)\n",
    "per_2T_0_opt = np.percentile(exp_1_opt['MSP-2'],PERCENTILES[0],axis=0)\n",
    "per_LM_0_opt = np.percentile(exp_1_opt['LogitsMargin'],PERCENTILES[0],axis=0)\n",
    "\n",
    "per_T_1_opt = np.percentile(exp_1_opt['T'],PERCENTILES[1],axis=0)\n",
    "per_p_1_opt = np.percentile(exp_1_opt['p'],PERCENTILES[1],axis=0)\n",
    "per_pT_1_opt = np.percentile(exp_1_opt['MSP-p'],PERCENTILES[1],axis=0)\n",
    "per_2T_1_opt = np.percentile(exp_1_opt['MSP-2'],PERCENTILES[1],axis=0)\n",
    "per_LM_1_opt = np.percentile(exp_1_opt['LogitsMargin'],PERCENTILES[1],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.axhline(baseline_mean,linestyle = '--', color = 'k', label = 'MSP')\n",
    "T_plot = plt.plot(sizes_sub,means_T,'.-', label = 'MSP-TS-AURC', color = 'blue')\n",
    "#T2_plot = plt.plot(sizes_sub,means_2T,'.-', label = 'MSP-pNorm (fixed p=2)', color = 'orange')\n",
    "pT_plot = plt.plot(sizes_sub,means_pT,'.-', label = 'MSP-pNorm', color = 'green')\n",
    "p_plot = plt.plot(sizes_sub,means_p,'.-', label = 'MaxLogit-pNorm', color = 'red')\n",
    "LM_plot = plt.plot(sizes_sub,means_LM,'.-', label = 'LogitsMargin', color = 'purple')\n",
    "LM_p_plot = plt.plot(sizes_sub,means_LM_p,'.-', label = 'LogitsMargin-pNorm', color = 'orange')\n",
    "\n",
    "\n",
    "#plt.fill_between(sizes_sub, min_p, max_p, facecolor=p_plot[0].get_color(), alpha=0.5)\n",
    "#plt.fill_between(sizes_sub, min_pT, max_pT, facecolor=pT_plot[0].get_color(), alpha=0.5)\n",
    "\n",
    "\n",
    "#plt.fill_between(sizes_sub, per_T_0, per_T_1, facecolor=T_plot[0].get_color(), alpha=0.2)\n",
    "#plt.fill_between(sizes_sub, per_pT_0, per_pT_1, facecolor=pT_plot[0].get_color(), alpha=0.2)\n",
    "#plt.fill_between(sizes_sub, per_p_0, per_p_1, facecolor=p_plot[0].get_color(), alpha=0.3)\n",
    "#plt.fill_between(sizes_sub, per_2T_0, per_2T_1, facecolor=T2_plot[0].get_color(), alpha=0.3)\n",
    "#plt.fill_between(sizes_sub[:-1], per_LM_0, per_LM_1, facecolor=LM_plot[0].get_color(), alpha=0.3)\n",
    "#plt.fill_between(sizes_sub[:-1], per_LM_p_0, per_LM_p_1, facecolor=LM_p_plot[0].get_color(), alpha=0.3)\n",
    "\n",
    "plt.fill_between(sizes_sub, means_T-std_T, means_T+std_T, facecolor=T_plot[0].get_color(), alpha=0.2)\n",
    "plt.fill_between(sizes_sub, means_pT-std_pT, means_pT+std_pT, facecolor=pT_plot[0].get_color(), alpha=0.2)\n",
    "plt.fill_between(sizes_sub, means_p-std_p, means_p+std_p, facecolor=p_plot[0].get_color(), alpha=0.3)\n",
    "#plt.fill_between(sizes_sub, per_2T_0, per_2T_1, facecolor=T2_plot[0].get_color(), alpha=0.3)\n",
    "plt.fill_between(sizes_sub, means_LM-std_LM, means_LM+std_LM, facecolor=LM_plot[0].get_color(), alpha=0.3)\n",
    "plt.fill_between(sizes_sub, means_LM_p-std_LM_p, means_LM_p+std_LM_p, facecolor=LM_p_plot[0].get_color(), alpha=0.3)\n",
    "\n",
    "\n",
    "plt.axhline(T_opt_mean,linestyle = '--', color = T_plot[0].get_color())\n",
    "plt.axhline(p_opt_mean,linestyle = '--', color = p_plot[0].get_color())\n",
    "plt.axhline(pT_opt_mean,linestyle = '--', color = pT_plot[0].get_color())\n",
    "#plt.axhline(T2_opt_mean,linestyle = '--', color = T2_plot[0].get_color())\n",
    "plt.axhline(LM_opt_mean,linestyle = '--', color = LM_plot[0].get_color())\n",
    "#plt.axhline(LM_p_opt_mean,linestyle = '--', color = LM_p_plot[0].get_color())\n",
    "\n",
    "plt.axhline(per_pT_0_opt,linestyle = ':', color = pT_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_pT_1_opt,linestyle = ':', color = pT_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "plt.axhline(per_T_0_opt,linestyle = ':', color = T_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_T_1_opt,linestyle = ':', color = T_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "plt.axhline(per_p_0_opt,linestyle = ':', color = p_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_p_1_opt,linestyle = ':', color = p_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "#plt.axhline(per_2T_0_opt,linestyle = ':', color = T2_plot[0].get_color(),linewidth = 1.0)\n",
    "#plt.axhline(per_2T_1_opt,linestyle = ':', color = T2_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "plt.axhline(per_LM_0_opt,linestyle = ':', color = LM_plot[0].get_color(),linewidth = 1.0)\n",
    "plt.axhline(per_LM_1_opt,linestyle = ':', color = LM_plot[0].get_color(),linewidth = 1.0)\n",
    "#plt.axhline(per_LM_p_0_opt,linestyle = ':', color = LM_p_plot[0].get_color(),linewidth = 1.0)\n",
    "#plt.axhline(per_LM_p_1_opt,linestyle = ':', color = LM_p_plot[0].get_color(),linewidth = 1.0)\n",
    "\n",
    "#plt.ylim(0.165,top=0.2)\n",
    "plt.ylim(0.19,top=0.38)\n",
    "plt.xlabel('Tuning set size')\n",
    "plt.ylabel('Test NAURC')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(os.path.join(FIGS_PATH, f'DataEfficiency_{MODEL_ARC}_{DATASET}.pdf'), transparent = True, format = 'pdf',bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
