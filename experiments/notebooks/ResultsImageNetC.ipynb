{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and pre-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MAIN_PATH = r'/home/luis-felipe'\n",
    "DATA_PATH = r'/home/luis-felipe/data'\n",
    "PATH_MODELS = os.path.join(MAIN_PATH,'torch_models')\n",
    "RESULTS_PATH = os.path.join(MAIN_PATH,'results')\n",
    "FIGS_PATH = os.path.join(MAIN_PATH,'results','figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contrário\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "SEED = 42\n",
    "#torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import models\n",
    "from utils import measures,metrics\n",
    "from data_utils import upload_logits,split_data\n",
    "import post_hoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = metrics.AURC#lambda x,y: 1-metrics.AUROC(x,y)#metrics.AURC\n",
    "DATASET = 'ImageNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruptions = os.listdir(os.path.join(DATA_PATH,DATASET,'corrupted'))\n",
    "lvls = range(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extras = ['speckle_noise', 'gaussian_blur','spatter','saturate']\n",
    "for c in extras:\n",
    "    corruptions.remove(c)\n",
    "print(len(corruptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sac = {c:[] for c in corruptions}\n",
    "d_sac_T = {c:[] for c in corruptions}\n",
    "d_sac_baseline = {c:[] for c in corruptions}\n",
    "\n",
    "acc = {c:[] for c in corruptions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.1\n",
    "for model_arc in ['resnet50']:#models.list_models():#models_list:\n",
    "    print(model_arc)\n",
    "    logits,labels = split_data.split_logits(*upload_logits(model_arc,DATASET,PATH_MODELS, \n",
    "                                    split = 'test', device = dev),VAL_SIZE,SEED)[:2]\n",
    "    risk = measures.wrong_class(logits,labels).float()\n",
    "    acc_baseline = 0.8086#1-risk.mean().item()\n",
    "    for corruption in corruptions:\n",
    "        for lvl in lvls:\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                logits_c,labels_c = split_data.split_logits(*upload_logits(model_arc,DATASET,PATH_MODELS, \n",
    "                                        split = ('corrupted',corruption,str(lvl)), device = dev, data_dir = DATA_PATH),VAL_SIZE,SEED)[2:]\n",
    "                \n",
    "                risk_c = measures.wrong_class(logits_c,labels_c).float()\n",
    "            \n",
    "                logits_c = post_hoc.centralize(logits_c)\n",
    "                logits = post_hoc.centralize(logits)\n",
    "                #except: \n",
    "                #    print('não deu')\n",
    "                #    continue\n",
    "                acc[corruption].append(1-risk_c.mean().item())\n",
    "                p = post_hoc.optimize.p(logits,risk,measures.max_logit,METRIC)\n",
    "                T = post_hoc.optimize.T(logits,risk,measures.MSP,METRIC)\n",
    "                d_sac[corruption].append(metrics.SAC(risk_c,post_hoc.MaxLogit_p(logits_c,p=p),acc_baseline))\n",
    "                d_sac_T[corruption].append(metrics.SAC(risk_c,measures.MSP(logits_c.div(T)),acc_baseline))\n",
    "                d_sac_baseline[corruption].append(metrics.SAC(risk_c,measures.MSP(logits_c),acc_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac = []\n",
    "sac_T = []\n",
    "sac_baseline = []\n",
    "for c in corruptions:\n",
    "    sac.append(d_sac[c])\n",
    "    sac_T.append(d_sac_T[c])\n",
    "    sac_baseline.append(d_sac_baseline[c])\n",
    "sac = np.array(sac)\n",
    "sac_T = np.array(sac_T)\n",
    "sac_baseline = np.array(sac_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corruptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
