{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and pre-definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "MAIN_PATH = r'/home/luis-felipe'\n",
    "DATA_PATH = r'/data'\n",
    "PATH_MODELS = os.path.join(MAIN_PATH,'torch_models')\n",
    "FIGS_PATH = os.path.join(MAIN_PATH,'results','figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o computador utilizado como cuda (gpu) se existir ou cpu caso contr√°rio\n",
    "print(torch.cuda.is_available())\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "SEED = 42\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '..')\n",
    "sys.path.insert(1, '../..')\n",
    "\n",
    "import models\n",
    "from utils import measures,metrics\n",
    "from data_utils import upload_logits,split_data\n",
    "import post_hoc\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = metrics.AURC#lambda x,y: 1-metrics.AUROC(x,y)#metrics.AURC\n",
    "DATASET = 'ImageNet'\n",
    "NUM_SPLITS = 10\n",
    "VAL_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = ['test','v2','sketch']#corrupted\n",
    "\n",
    "corruptions = os.listdir(os.path.join(DATA_PATH,DATASET,'corrupted'))\n",
    "extras = ['speckle_noise', 'gaussian_blur','spatter','saturate']\n",
    "for c in extras:\n",
    "    corruptions.remove(c)\n",
    "lvls = range(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "acc = {s: defaultdict(list) for s in shifts}\n",
    "\n",
    "sac_opt = {s: defaultdict(list) for s in shifts}\n",
    "naurc_opt = {s: defaultdict(list) for s in shifts}\n",
    "naurc_baseline = {s: defaultdict(list) for s in shifts}\n",
    "sac_baseline = {s: defaultdict(list) for s in shifts}\n",
    "\n",
    "p_list = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc['corrupted'] = {c:{lvl:defaultdict(list) for lvl in lvls} for c in corruptions}\n",
    "naurc_opt['corrupted'] = {c:{lvl:defaultdict(list) for lvl in lvls} for c in corruptions}\n",
    "sac_opt['corrupted'] = {c:{lvl:defaultdict(list) for lvl in lvls} for c in corruptions}\n",
    "naurc_baseline['corrupted'] = {c:{lvl:defaultdict(list) for lvl in lvls} for c in corruptions}\n",
    "sac_baseline['corrupted'] = {c:{lvl:defaultdict(list) for lvl in lvls} for c in corruptions}\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "models_list = models.list_models()#['resnet50','vgg16','alexnet','efficientnetv2_xl','efficientnet_b3','convnext_base','resnet18','vit_l_16_384','vit_b_32_sam','wide_resnet50_2','maxvit_t']\n",
    "seed = SEED\n",
    "for i in range(NUM_SPLITS):\n",
    "    print(i)\n",
    "    for model_arc in models_list:\n",
    "        print(model_arc)\n",
    "        with torch.no_grad():\n",
    "            logits_val,labels_val,logits_test,labels_test = split_data.split_logits(*upload_logits(model_arc,DATASET,PATH_MODELS, \n",
    "                                split = 'test', device = dev),VAL_SIZE,seed = seed)\n",
    "            logits_val = post_hoc.centralize(logits_val)\n",
    "            logits_test = post_hoc.centralize(logits_test)\n",
    "            risk_val = measures.wrong_class(logits_val,labels_val).float()\n",
    "            risk_test = measures.wrong_class(logits_test,labels_test).float()\n",
    "        \n",
    "        acc_iid= (1-risk_test.mean().item())\n",
    "        p = post_hoc.optimize.p(logits_val,risk_val,measures.max_logit,METRIC)\n",
    "        fallback = (metrics.N_AURC(risk_val,measures.MSP(logits_val)) < metrics.N_AURC(risk_val,post_hoc.MaxLogit_p(logits_val,p)))\n",
    "        if fallback: p_list[model_arc].append('MSP')\n",
    "        else: p_list[model_arc].append(p.item())\n",
    "        \n",
    "        for shift in shifts:          \n",
    "            if shift =='test':\n",
    "                logits_shift,labels_shift = logits_test,labels_test\n",
    "            else:    \n",
    "                logits_shift,labels_shift = upload_logits(model_arc,DATASET,PATH_MODELS, \n",
    "                                        split = shift, device = dev,data_dir = DATA_PATH)\n",
    "            \n",
    "            logits_shift = post_hoc.centralize(logits_shift)\n",
    "            risk_shift = measures.wrong_class(logits_shift,labels_shift).float()\n",
    "            acc[shift][model_arc].append((1-risk_shift.mean().item()))\n",
    "            \n",
    "            \n",
    "            naurc_baseline[shift][model_arc].append(metrics.N_AURC(risk_shift,measures.MSP(logits_shift)))\n",
    "            sac_baseline[shift][model_arc].append(metrics.SAC(risk_shift,measures.MSP(logits_shift),acc_iid))\n",
    "            \n",
    "            if fallback:\n",
    "                naurc_opt[shift][model_arc].append(metrics.N_AURC(risk_shift,measures.MSP(logits_shift)))\n",
    "                sac_opt[shift][model_arc].append(metrics.SAC(risk_shift,measures.MSP(logits_shift),acc_iid))\n",
    "            else:\n",
    "                naurc_opt[shift][model_arc].append(metrics.N_AURC(risk_shift,post_hoc.MaxLogit_p(logits_shift,p)))\n",
    "                sac_opt[shift][model_arc].append(metrics.SAC(risk_shift,post_hoc.MaxLogit_p(logits_shift,p),acc_iid))\n",
    "        if model_arc in ['resnet50','alexnet','wide_resnet50_2','convnext_large','vgg11','efficientnet_b3']: \n",
    "            for corruption in corruptions:\n",
    "                for lvl in lvls:\n",
    "\n",
    "                    logits_shift,labels_shift = split_data.split_logits(*upload_logits(model_arc,DATASET,PATH_MODELS, \n",
    "                            split = ('corrupted',corruption,str(lvl)), device = dev),VAL_SIZE,seed = seed)[-2:]\n",
    "                    logits_shift = post_hoc.centralize(logits_shift)\n",
    "                    risk_shift = measures.wrong_class(logits_shift,labels_shift).float()\n",
    "                    acc['corrupted'][corruption][lvl][model_arc].append((1-risk_shift.mean().item()))\n",
    "\n",
    "                    naurc_baseline['corrupted'][corruption][lvl][model_arc].append(metrics.N_AURC(risk_shift,measures.MSP(logits_shift)))\n",
    "                    sac_baseline['corrupted'][corruption][lvl][model_arc].append(metrics.SAC(risk_shift,measures.MSP(logits_shift),acc_iid))\n",
    "\n",
    "                    if fallback:\n",
    "                        naurc_opt['corrupted'][corruption][lvl][model_arc].append(metrics.N_AURC(risk_shift,measures.MSP(logits_shift)))\n",
    "                        sac_opt['corrupted'][corruption][lvl][model_arc].append(metrics.SAC(risk_shift,measures.MSP(logits_shift),acc_iid))\n",
    "                    else:\n",
    "                        naurc_opt['corrupted'][corruption][lvl][model_arc].append(metrics.N_AURC(risk_shift,post_hoc.MaxLogit_p(logits_shift,p)))\n",
    "                        sac_opt['corrupted'][corruption][lvl][model_arc].append(metrics.SAC(risk_shift,post_hoc.MaxLogit_p(logits_shift,p),acc_iid))\n",
    "                \n",
    "            \n",
    "            \n",
    "    seed+=10\n",
    "models_list = list(acc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "naurc_c_opt = {lvl:[] for lvl in lvls}\n",
    "naurc_c_baseline = {lvl:[] for lvl in lvls}\n",
    "acc_c = {lvl:[] for lvl in lvls}\n",
    "naurc_opt_mean = {lvl:[] for lvl in lvls}\n",
    "naurc_baseline_mean = {lvl:[] for lvl in lvls}\n",
    "acc_mean = {lvl:[] for lvl in lvls}\n",
    "naurc_opt_std = {lvl:[] for lvl in lvls}\n",
    "naurc_baseline_std = {lvl:[] for lvl in lvls}\n",
    "for lvl in shifts+list(lvls):\n",
    "    if isinstance(lvl,int):\n",
    "        for c in corruptions:\n",
    "            naurc_c_opt[lvl].append(list(naurc_opt['corrupted'][c][lvl].values()))\n",
    "            naurc_c_baseline[lvl].append(list(naurc_baseline['corrupted'][c][lvl].values()))\n",
    "            acc_c[lvl].append(list(acc['corrupted'][c][lvl].values()))\n",
    "        naurc_opt[lvl] = {m:np.mean(naurc_c_opt[lvl],0)[i] for i,m in enumerate(naurc_opt['corrupted'][c][lvl])}\n",
    "        naurc_baseline[lvl] = {m:np.mean(naurc_c_baseline[lvl],0)[i] for i,m in enumerate(naurc_baseline['corrupted'][c][lvl])}\n",
    "        acc[lvl] = {m:np.mean(acc_c[lvl],0)[i] for i,m in enumerate(acc['corrupted'][c][lvl])}\n",
    "    \n",
    "    acc_mean[lvl] = np.mean(list(acc[lvl].values()),-1)\n",
    "    naurc_opt_mean[lvl] = np.mean(list(naurc_opt[lvl].values()),-1)\n",
    "    naurc_baseline_mean[lvl] = np.mean(list(naurc_baseline[lvl].values()),-1)\n",
    "    naurc_opt_std[lvl] = np.std(list(naurc_opt[lvl].values()),-1)\n",
    "    naurc_baseline_std[lvl] = np.std(list(naurc_baseline[lvl].values()),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {lvl: f\"Imagenet-C - {lvl}\" for lvl in lvls}\n",
    "labels['v2'] = 'ImageNetV2'\n",
    "labels['test'] = 'ImageNet (ID)'\n",
    "labels['sketch'] = 'ImageNet Sketch'\n",
    "\n",
    "marker = {lvl: '^' for lvl in lvls}\n",
    "marker['v2'] = 'x'\n",
    "marker['test'] = 'o'\n",
    "marker['sketch'] = '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize = (10,4), sharey = True, sharex = True)\n",
    "fig.tight_layout(w_pad = -1)\n",
    "\n",
    "for lvl in shifts+list(lvls):\n",
    "    if lvl =='sketch': continue\n",
    "    scatter = axes[0].scatter(acc_mean[lvl],\n",
    "                          naurc_baseline_mean[lvl],marker = marker[lvl],label = labels[lvl])\n",
    "\n",
    "    axes[1].scatter(acc_mean[lvl],\n",
    "                    naurc_opt_mean[lvl],marker = marker[lvl],label = labels[lvl])\n",
    "#for i in range(5):\n",
    "#    axes[1].scatter(accs_c.mean(0)[i],naurc_p_c.mean(0)[i],marker = '^',label = i)\n",
    "#    axes[0].scatter(accs_c.mean(0)[i],baseline_c.mean(0)[i],marker = '^',label = i)\n",
    "#$\\rho$={spearmanr(np.array(list(acc.values())).mean(-1),optimal_naurc).correlation:.4f}\n",
    "axes[0].set_title(rf'Baseline',fontsize = 15)\n",
    "axes[1].set_title(rf'Optimized',fontsize = 15)\n",
    "axes[0].set_ylabel('NAURC',fontsize = 15)\n",
    "for ax in axes:\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('Accuracy',fontsize = 15)\n",
    "    ax.tick_params(axis='both',  labelsize=13)\n",
    "axes[1].legend(prop={'size': 13})\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(FIGS_PATH,'NAURC_shift.pdf'),format = 'pdf', bbox_inches='tight', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,4))\n",
    "scatter = plt.scatter(naurc_baseline_mean['test'],naurc_baseline_mean['v2'], c = 'red', marker = 'x', alpha = 0.5, label = 'Baseline')\n",
    "scatter = plt.scatter(naurc_opt_mean['test'],naurc_opt_mean['v2'], c = 'blue', marker = 'o', label = 'Optimized')\n",
    "\n",
    "naurc_opt_mean[lvl]\n",
    "plt.plot([0.15,0.45],[0.15,0.45],'k--')\n",
    "plt.xlabel('NAURC ImageNet (IID)',fontsize = 15)\n",
    "plt.ylabel('NAURC ImageNetV2',fontsize = 15)\n",
    "plt.grid()\n",
    "\n",
    "legend1 = plt.legend(prop={'size': 10})\n",
    "plt.tick_params(axis='both',  labelsize=13)\n",
    "plt.savefig(os.path.join(FIGS_PATH,'NAURC_consistency.pdf'),format = 'pdf', bbox_inches='tight', transparent = True)\n",
    "plt.show()\n",
    "\n",
    "print('Pearson Correlation = ', pearsonr(np.r_[naurc_opt_mean['test'],naurc_baseline_mean['test']],np.r_[naurc_opt_mean['v2'],naurc_baseline_mean['v2']]).correlation)\n",
    "#print('Pearson Correlation = ', pearsonr(naurc_opt_mean['test'],naurc_opt_mean['v2']).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = {}\n",
    "for lvl,v in naurc_opt_mean.items():\n",
    "    gains[lvl] = naurc_baseline_mean[lvl] - v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "p_list_mode = {}\n",
    "for m,p in p_list.items():\n",
    "    p_list_mode[m] = Counter(p).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,4))\n",
    "scatter = plt.scatter(gains['test'],gains['v2'], c = [-1 if x=='MSP' else x for x in p_list_mode.values()])\n",
    "plt.plot([0,0.3],[0,0.3],'k--')\n",
    "plt.xlabel('Gain ImageNet (IID)',fontsize = 15)\n",
    "plt.ylabel('Gain ImageNetV2',fontsize = 15)\n",
    "plt.grid()\n",
    "\n",
    "l = scatter.legend_elements()[1]\n",
    "for n,i in enumerate(l):\n",
    "    l[n] = 'p = '+i \n",
    "l[0] = 'MSP'\n",
    "\n",
    "legend1 = plt.legend(scatter.legend_elements()[0], l, prop={'size': 10})\n",
    "plt.tick_params(axis='both',  labelsize=13)\n",
    "plt.savefig(os.path.join(FIGS_PATH,'gains_v2.pdf'),format = 'pdf', bbox_inches='tight', transparent = True)\n",
    "plt.show()\n",
    "\n",
    "print('Pearson Correlation = ', pearsonr(gains['test'],gains['v2']).correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
